<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Robot Control | Mingyang Xu</title>
    <link>https://mingyangxu.netlify.app/tag/robot-control/</link>
      <atom:link href="https://mingyangxu.netlify.app/tag/robot-control/index.xml" rel="self" type="application/rss+xml" />
    <description>Robot Control</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><lastBuildDate>Wed, 15 Mar 2023 04:16:37 +0000</lastBuildDate>
    <image>
      <url>https://mingyangxu.netlify.app/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Robot Control</title>
      <link>https://mingyangxu.netlify.app/tag/robot-control/</link>
    </image>
    
    <item>
      <title>Ankle-assist Robot with Gait-adaptive Control Method</title>
      <link>https://mingyangxu.netlify.app/project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/</link>
      <pubDate>Wed, 15 Mar 2023 04:16:37 +0000</pubDate>
      <guid>https://mingyangxu.netlify.app/project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/re1_hu30934fcd6595e064cfa40c422f24395a_2070850_5a7b0eec398f255ca8f7476a0451f22f.webp 400w,
               /project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/re1_hu30934fcd6595e064cfa40c422f24395a_2070850_58aa461f41c950739cd76561da329177.webp 760w,
               /project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/re1_hu30934fcd6595e064cfa40c422f24395a_2070850_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/re1_hu30934fcd6595e064cfa40c422f24395a_2070850_5a7b0eec398f255ca8f7476a0451f22f.webp&#34;
               width=&#34;760&#34;
               height=&#34;422&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;As the population ages, the number of elderly people suffering from systemic diseases such as stroke increases. To address this problem, various wearable walking assistive robots have been developed to promote physical exercise for stroke prevention. Wearable assistive robots have shown the ability to improve human mobility. However, most of these robots are heavy, bulky, and impractical. &lt;strong&gt;In this study, we developed a compact ankle assistive robot for elderly users to promote walking exercise.&lt;/strong&gt; By informing the user of correct motion and timing, the robot can guide the user to achieve a healthy gait by only assisting their ankle joint. The robot provides faster-than-ankle motion to allow the user to feel supported while walking. Users can adjust the robot’s assistance parameters through a graphical user interface (GUI) according to their demands. Furthermore, &lt;strong&gt;we proposed a gait-adaptive method for ankle assistive robots to adapt to the user’s changing gait.&lt;/strong&gt; Hence, the robot can automatically adjust the parameters to provide more accurate walking assistance. Finally, the results of an evaluation experiment demonstrated the positive feasibility of human gait adaptation. The proposed methods have the advantages of low cost and easy implementation.&lt;/p&gt;
&lt;h1 id=&#34;demo&#34;&gt;D﻿emo&lt;/h1&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-robot-operates-in-normal-mode-the-robot-provides-constant-walking-assistance-to-the-user&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Robot operates in normal mode, the robot provides constant walking assistance to the user&#34;
           src=&#34;https://mingyangxu.netlify.app/project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/REGIF1.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Robot operates in normal mode, the robot provides constant walking assistance to the user
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-robot-operates-in-gait-adaptive-mode-the-robot-adjusts-the-assistance-automatically-to-adapt-to-the-users-changing-gait&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Robot operates in gait-adaptive mode, the robot adjusts the assistance automatically to adapt to the user’s changing gait&#34;
           src=&#34;https://mingyangxu.netlify.app/project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/REGIF2.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Robot operates in gait-adaptive mode, the robot adjusts the assistance automatically to adapt to the user’s changing gait
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-users-can-adjust-the-assistance-mode-and-assistance-parameter-by-the-developed-gui&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Users can adjust the assistance mode and assistance parameter by the developed GUI&#34;
           src=&#34;https://mingyangxu.netlify.app/project/imanta-bionic-aerial-robot-shows-on-2017-national-youth-college-science-camp/GUI1.gif&#34;
           loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Users can adjust the assistance mode and assistance parameter by the developed GUI
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;related-publications&#34;&gt;R﻿elated Publications&lt;/h1&gt;
&lt;p&gt;[1] &lt;strong&gt;M. Xu&lt;/strong&gt;, Y. Hua, Y. Li, J. Zhuang, K. Osawa, K. Nakagawa, H. Lee, L. Yuge, E. Tanaka, “Development of an Ankle Assistive Robot with Instantly Gait-Adaptive Method,” in &lt;em&gt;Journal of Robotics and Mechatronics (JRM)&lt;/em&gt;, 2023. (Accepted)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Control Method for Walking Assistive Robot Based on Emotion and Fatigue Detection</title>
      <link>https://mingyangxu.netlify.app/project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/</link>
      <pubDate>Sat, 10 Sep 2022 04:05:58 +0000</pubDate>
      <guid>https://mingyangxu.netlify.app/project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as1_huc7686695b4c9d35c96d368554cd83de8_619596_82af4f180165d1a29568a833818772da.webp 400w,
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as1_huc7686695b4c9d35c96d368554cd83de8_619596_b22898189fdc5430f88dbc4bd959283b.webp 760w,
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as1_huc7686695b4c9d35c96d368554cd83de8_619596_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as1_huc7686695b4c9d35c96d368554cd83de8_619596_82af4f180165d1a29568a833818772da.webp&#34;
               width=&#34;760&#34;
               height=&#34;423&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;The purpose of this study is to develop a control system for walking assistive robot that enables the user to keep positive emotions and maintain high levels of motivation during exercise.&lt;/strong&gt; In this study, a control method based on emotion recognition and fatigue detection was proposed. We used &lt;strong&gt;brainwave and heartbeat signals&lt;/strong&gt; to train a deep neural network (DNN) model to recognize users’ emotions. &lt;strong&gt;Portable near-infrared spectroscopy (NIRS)&lt;/strong&gt; was used to detect muscle fatigue. Furthermore, we established a 3D human state model to evaluate the user’s emotional and fatigue states. We also performed experiments to evaluate the ability of the control method to improve the effect of walking exercise.&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-control-process-of-the-walking-assistive-system&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Control process of the walking assistive system&#34; srcset=&#34;
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as2_hue9dfd38e01b8353183f2422edb1680bc_1537899_e3a1d109c6afb6dbe1cc9ed0bf824252.webp 400w,
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as2_hue9dfd38e01b8353183f2422edb1680bc_1537899_5512c8816e0ab0750aede674979739db.webp 760w,
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as2_hue9dfd38e01b8353183f2422edb1680bc_1537899_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as2_hue9dfd38e01b8353183f2422edb1680bc_1537899_e3a1d109c6afb6dbe1cc9ed0bf824252.webp&#34;
               width=&#34;760&#34;
               height=&#34;507&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Control process of the walking assistive system
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-flow-diagram-of-the-real-time-emotion-recognition-system&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Flow diagram of the real-time emotion recognition system&#34; srcset=&#34;
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as3_hu168ce9fbbeafdc7a27efb5d95184ef30_1006565_1e9d5f7e186b31cbee44310b205d445e.webp 400w,
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as3_hu168ce9fbbeafdc7a27efb5d95184ef30_1006565_b2222b078a55d5c443898e16d799935a.webp 760w,
               /project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as3_hu168ce9fbbeafdc7a27efb5d95184ef30_1006565_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/mingyang-xu-was-invited-to-make-a-report-at-2018-student-technology-innovation-forum-of-beihang-university/as3_hu168ce9fbbeafdc7a27efb5d95184ef30_1006565_1e9d5f7e186b31cbee44310b205d445e.webp&#34;
               width=&#34;760&#34;
               height=&#34;282&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Flow diagram of the real-time emotion recognition system
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;related-publications&#34;&gt;Related Publications:&lt;/h1&gt;
&lt;p&gt;[1] Y. Li, &lt;strong&gt;M. Xu&lt;/strong&gt;, K. Osawa, E. Tanaka, “A Control Method for Walking Assistance Robot Considering Emotion and Body Condition,” in JSME-IIP/ASME-ISPS Joint International Conference on Micromechatronics for Information and Precision Equipment (MIPE 2022), A1-1-03, 2022.&lt;/p&gt;
&lt;p&gt;[2] Y. Wei, Y. Li, &lt;strong&gt;M. Xu&lt;/strong&gt;, Y. Gong, K. Osawa, E. Tanaka, “A Real-Time and Two-Dimensional Emotion Recognition System Based on EEG and HRV Using Machine Learning,” in IEEE/SICE International Symposium on System Integrations (SII 2023), Atlanta, GA, USA, 2023, pp. 1-6.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Terrain-adaptive Aerial Robot with Legged Landing Gear</title>
      <link>https://mingyangxu.netlify.app/project/terrain-adaptive-aerial-robot/</link>
      <pubDate>Sun, 20 May 2018 04:12:23 +0000</pubDate>
      <guid>https://mingyangxu.netlify.app/project/terrain-adaptive-aerial-robot/</guid>
      <description>&lt;p&gt;&lt;strong&gt;Members:&lt;/strong&gt; Mingyang Xu, Yunkai Qi, Jin Zhu, Wanhe An, Dada Hu, Jiaxuan Zhang, Shiqi Sun&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Supervisor:&lt;/strong&gt; Prof. Tianmiao Wang&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/terrain-adaptive-aerial-robot/la0_hu58fc55ce737ddd39e288094ee9b7622f_3818586_b6579eb17eadfbbe1e1e0473777a6e27.webp 400w,
               /project/terrain-adaptive-aerial-robot/la0_hu58fc55ce737ddd39e288094ee9b7622f_3818586_c28f2812607b50e45c1107958516afbb.webp 760w,
               /project/terrain-adaptive-aerial-robot/la0_hu58fc55ce737ddd39e288094ee9b7622f_3818586_1200x1200_fit_q75_h2_lanczos_3.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/terrain-adaptive-aerial-robot/la0_hu58fc55ce737ddd39e288094ee9b7622f_3818586_b6579eb17eadfbbe1e1e0473777a6e27.webp&#34;
               width=&#34;760&#34;
               height=&#34;391&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;h1 id=&#34;abstract&#34;&gt;Abstract&lt;/h1&gt;
&lt;p&gt;Vertical take-off and landing aircrafts (VTOLs) are widely used in transport and rescue tasks because of their ability to perform vertical takeoffs and landings. &lt;strong&gt;However, the possibility of off-field landings is severely limited by non-flat landing areas. Some example landing areas include great slopes, rocky grounds, and stairs.&lt;/strong&gt; VTOL-type aerial robots that use conventional skids or landing wheels have poor ability to adapt to uneven and steep terrain, causing safety problems and economic losses. Aiming at the above limitations, we proposed a novel terrain-adaptive aerial robot. This aerial robot features robotic landing gear, which consists of four legs. Based on the force, attitude, and height data collected by the sensors, the landing gear could be automatically adjusted to conform closely with the ground, thus &lt;strong&gt;keeping the robot horizontal and balanced during landing&lt;/strong&gt;. Finally, the laboratory experiment test and outfield flight test have been done to verify the results of the design and theory modelling.&lt;/p&gt;
&lt;h1 id=&#34;video&#34;&gt;Video&lt;/h1&gt;

&lt;div style=&#34;position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;&#34;&gt;
  &lt;iframe src=&#34;https://www.youtube.com/embed/uX7zKS1Cb6I&#34; style=&#34;position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;&#34; allowfullscreen title=&#34;YouTube Video&#34;&gt;&lt;/iframe&gt;
&lt;/div&gt;

&lt;p&gt;















&lt;figure  id=&#34;figure-overview-of-developed-prototypes&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Overview of developed prototypes&#34; srcset=&#34;
               /project/terrain-adaptive-aerial-robot/la1_hu5e01a03e094f69a818aaa342ee05f2d5_4859023_8d61c51fe5bbdf514ec6a5b4a8121dde.webp 400w,
               /project/terrain-adaptive-aerial-robot/la1_hu5e01a03e094f69a818aaa342ee05f2d5_4859023_a8eebb740faee4f07e23ab0b7c54dc77.webp 760w,
               /project/terrain-adaptive-aerial-robot/la1_hu5e01a03e094f69a818aaa342ee05f2d5_4859023_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/terrain-adaptive-aerial-robot/la1_hu5e01a03e094f69a818aaa342ee05f2d5_4859023_8d61c51fe5bbdf514ec6a5b4a8121dde.webp&#34;
               width=&#34;760&#34;
               height=&#34;474&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Overview of developed prototypes
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  id=&#34;figure-process-of-the-terrain-adaptive-landing-mode&#34;&gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;Process of the terrain-adaptive landing mode&#34; srcset=&#34;
               /project/terrain-adaptive-aerial-robot/la2_hu6557e5424d72559578666f56dbc99953_1138255_3a176cc15e907f79b4848bac300506bb.webp 400w,
               /project/terrain-adaptive-aerial-robot/la2_hu6557e5424d72559578666f56dbc99953_1138255_f07a90e0e49492cc3ef1bd8d5735b3ac.webp 760w,
               /project/terrain-adaptive-aerial-robot/la2_hu6557e5424d72559578666f56dbc99953_1138255_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/terrain-adaptive-aerial-robot/la2_hu6557e5424d72559578666f56dbc99953_1138255_3a176cc15e907f79b4848bac300506bb.webp&#34;
               width=&#34;760&#34;
               height=&#34;502&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;figcaption&gt;
      Process of the terrain-adaptive landing mode
    &lt;/figcaption&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img alt=&#34;&#34; srcset=&#34;
               /project/terrain-adaptive-aerial-robot/group_hu3c059915d182fd95be66963e11dd0e80_265165_36154b6daa2d27081a0765b4ad436c42.webp 400w,
               /project/terrain-adaptive-aerial-robot/group_hu3c059915d182fd95be66963e11dd0e80_265165_2fec19e8ed630e020216aa3c7ab68165.webp 760w,
               /project/terrain-adaptive-aerial-robot/group_hu3c059915d182fd95be66963e11dd0e80_265165_1200x1200_fit_q75_h2_lanczos.webp 1200w&#34;
               src=&#34;https://mingyangxu.netlify.app/project/terrain-adaptive-aerial-robot/group_hu3c059915d182fd95be66963e11dd0e80_265165_36154b6daa2d27081a0765b4ad436c42.webp&#34;
               width=&#34;760&#34;
               height=&#34;105&#34;
               loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
